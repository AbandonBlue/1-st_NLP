{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 作業目的:了解決策樹的節點分支依據\n",
    "本次作業可參考簡報中的延伸閱讀[訊息增益](https://medium.com/jameslearningnote/%E8%B3%87%E6%96%99%E5%88%86%E6%9E%90-%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E7%AC%AC3-5%E8%AC%9B-%E6%B1%BA%E7%AD%96%E6%A8%B9-decision-tree-%E4%BB%A5%E5%8F%8A%E9%9A%A8%E6%A9%9F%E6%A3%AE%E6%9E%97-random-forest-%E4%BB%8B%E7%B4%B9-7079b0ddfbda)部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question:\n",
    "若你是決策樹，下列兩種分類狀況(a,b)，你會選擇哪種做分類？為什麼？\n",
    "\n",
    "<img src='hw_1.png' style='width:500px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer:\n",
    "\n",
    "###your answer###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T11:03:46.568460Z",
     "start_time": "2021-03-15T11:03:46.547460Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IG from (a) 0.18872187554086717\n",
      "IG from (b) 0.13792538097002993\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def entropy(nums: list):\n",
    "    num_total = sum(nums)\n",
    "    ans = 0\n",
    "    for num in nums:\n",
    "        p = num / num_total\n",
    "        if p == 0:\n",
    "            continue\n",
    "        ans -= (p * np.log2(p))\n",
    "    return ans\n",
    "\n",
    "# (a)\n",
    "ig_a = entropy([20, 20]) - (0.5 * entropy([15, 5]) + 0.5 * entropy([5, 15]))\n",
    "ig_b = entropy([20, 20]) - (35/40*entropy([15, 20]) + 5/40*entropy([5, 0]))\n",
    "\n",
    "print('IG from (a)', ig_a)\n",
    "print('IG from (b)', ig_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T11:18:50.389663Z",
     "start_time": "2021-03-15T11:18:50.368669Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IG from (a) 0.125\n",
      "IG from (b) 0.0714285714285714\n"
     ]
    }
   ],
   "source": [
    "def gini(nums: list):\n",
    "    num_total = sum(nums)\n",
    "    ans = 1\n",
    "    for num in nums:\n",
    "        p = num / num_total\n",
    "        ans -= p**2\n",
    "    return ans\n",
    "\n",
    "# (a)\n",
    "ig_a = gini([20, 20]) - (0.5 * gini([15, 5]) + 0.5 * gini([5, 15]))\n",
    "ig_b = gini([20, 20]) - (35/40*gini([15, 20]) + 5/40*gini([5, 0]))\n",
    "\n",
    "print('IG from (a)', ig_a)\n",
    "print('IG from (b)', ig_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 選擇(a), 因為根據Information gain, (a)把資料的混亂程度下降比較多!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 閱讀作業\n",
    "\n",
    "決策樹根據計算分割準則的不同(ex: Entropy, Gini, Gain ratio)，可分為ID3, C4.5, CART樹的算法，請同學閱讀下列文章，來更加了解決策樹的算法。\n",
    "\n",
    "[決策樹(ID3, C4.5, CART)](https://blog.csdn.net/u010089444/article/details/53241218)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python37364bit6893c7013b164b1189a865dcaea9fb2f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
