{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 瞭解如何使用計數方法詞向量與SVD\n",
    "\n",
    "再將文字資料輸入模型進行自然語言任務之前，其中一項重要的前處理即為將字詞向量化(詞嵌入word embedding)。 而將詞向量化的方法有很多，這裡我們會著重在介紹如何使用計數方法來將字詞向量化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 字詞前處理\n",
    "\n",
    "在進行字詞向量化之前，我們需要針對文本資料進行前置處理，將**文本資料分割成字詞(斷詞)**，再將分割後的**字詞轉換成字詞ID清單**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T12:25:42.484277Z",
     "start_time": "2021-01-27T12:25:41.584401Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed corpus: [[0 6 2 4 3 6 1 5]] \n",
      " word2idx: {'you': 0, 'hello': 1, 'goodbye': 2, 'i': 3, 'and': 4, '.': 5, 'say': 6} \n",
      " idx2word: {0: 'you', 1: 'hello', 2: 'goodbye', 3: 'i', 4: 'and', 5: '.', 6: 'say'}\n"
     ]
    }
   ],
   "source": [
    "#導入會使用的library\n",
    "import re\n",
    "import numpy as np\n",
    "from typing import List\n",
    "\n",
    "#定義前處理函式\n",
    "def preprocess(corpus: List[str], only_word: bool = False):\n",
    "    '''Function to do preprocess of input corpus\n",
    "    Parameters\n",
    "    -----------\n",
    "    corpus: str\n",
    "        input corpus to be processed\n",
    "    only_word: bool\n",
    "        whether to filter out non-word\n",
    "    '''\n",
    "    word_dic = set()\n",
    "    processed_sentence = []\n",
    "    \n",
    "    for sentence in corpus:\n",
    "        #將所有字詞轉為小寫\n",
    "        sentence = sentence.lower()\n",
    "\n",
    "        #移除標點符號(可以依據使用狀況決定是否要移除標點符號)\n",
    "        if only_word:\n",
    "            pattern = r'[^\\W_]+'\n",
    "            sentence = re.findall(pattern, sentence)\n",
    "        else:\n",
    "            punctuation_list = ['.', ',', '!', '?']\n",
    "            for pun in punctuation_list:\n",
    "                sentence = sentence.replace(pun, ' '+pun)\n",
    "            sentence = sentence.split(' ')\n",
    "        \n",
    "        #添加字詞到字典中\n",
    "        word_dic |= set(sentence)\n",
    "        processed_sentence.append(sentence)\n",
    "    \n",
    "    \n",
    "    #建立字詞ID清單\n",
    "    word2idx = dict()\n",
    "    idx2word = dict()\n",
    "    for word in word_dic:\n",
    "        if word not in word2idx:\n",
    "            idx = len(word2idx)\n",
    "            word2idx[word] = idx\n",
    "            idx2word[idx] = word\n",
    "\n",
    "    #將文本轉為ID型式\n",
    "    id_mapping = lambda x: word2idx[x]\n",
    "    \n",
    "    corpus = np.array([list(map(id_mapping, sentence)) for sentence in processed_sentence])\n",
    "\n",
    "    return corpus, word2idx, idx2word\n",
    "\n",
    "#定義簡易文本資料(使用Ch17講義中的例子)\n",
    "corpus = ['You say goodbye and I say hello.']\n",
    "\n",
    "processed_corpus, word2idx, idx2word = preprocess(corpus)\n",
    "print(f'Processed corpus: {processed_corpus} \\n word2idx: {word2idx} \\n idx2word: {idx2word}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 共現矩陣\n",
    "將轉化處理過的文本資料轉化為共現矩陣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T12:26:29.684745Z",
     "start_time": "2021-01-27T12:26:29.659702Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 1, 1],\n",
       "       [1, 0, 0, 1, 1, 0, 1],\n",
       "       [0, 1, 1, 0, 1, 0, 1],\n",
       "       [0, 0, 1, 1, 0, 0, 2],\n",
       "       [0, 1, 0, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 2, 1, 0]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#定義共現矩陣函式\n",
    "def create_co_matrix(corpus: np.ndarray, vocab_size: int, window_size: int=1):\n",
    "    '''\n",
    "    '''\n",
    "    # initialize co-occurrence matrix\n",
    "    co_matrix = np.zeros(shape=(vocab_size, vocab_size), dtype=np.int32)\n",
    "    \n",
    "    for sentence in corpus:\n",
    "        sentence_size = len(sentence)\n",
    "    \n",
    "        for idx, word_id in enumerate(sentence):\n",
    "            for i in range(1, window_size+1):\n",
    "                left_idx = idx - i\n",
    "                right_idx = idx + i\n",
    "\n",
    "                if left_idx >= 0:\n",
    "                    left_word_id = sentence[left_idx]\n",
    "                    co_matrix[word_id, left_word_id] += 1\n",
    "\n",
    "                if right_idx < sentence_size:\n",
    "                    right_word_id = sentence[right_idx]\n",
    "                    co_matrix[word_id, right_word_id] += 1\n",
    "                \n",
    "    return co_matrix\n",
    "\n",
    "co_matrix = create_co_matrix(processed_corpus, len(word2idx), 2)\n",
    "co_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T12:26:38.832809Z",
     "start_time": "2021-01-27T12:26:38.820269Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 1, 1],\n",
       "       [1, 0, 0, 1, 1, 0, 1],\n",
       "       [0, 1, 1, 0, 1, 0, 1],\n",
       "       [0, 0, 1, 1, 0, 0, 2],\n",
       "       [0, 1, 0, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 2, 1, 0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定義共現矩陣函式\n",
    "# method two\n",
    "\n",
    "def create_co_matrix(corpus: np.ndarray, vocab_size: int, window_size: int=1):\n",
    "    '''\n",
    "    '''\n",
    "    # initialize co-occurrence matrix\n",
    "    co_matrix = np.zeros(shape=(vocab_size, vocab_size), dtype=np.int32)\n",
    "    \n",
    "    for sentence in corpus:\n",
    "        sentence_size = len(sentence)\n",
    "    \n",
    "        for idx, word_id in enumerate(sentence):\n",
    "            left_idx = idx - window_size if idx - window_size >= 0 else 0\n",
    "            context_ids = sentence[left_idx:idx]\n",
    "            \n",
    "            for left_i, left_id in enumerate(context_ids):\n",
    "                co_matrix[word_id, left_id] += 1\n",
    "                co_matrix[left_id, word_id] += 1\n",
    "\n",
    "    return co_matrix\n",
    "\n",
    "co_matrix = create_co_matrix(processed_corpus, len(word2idx), 2)\n",
    "co_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 向量間相似度\n",
    "比較轉換為向量的字詞的方法有很多種，其中當要表示字詞的相似度時，最常使用的方法為餘弦相似度 (Cosine Similarity)\n",
    "\n",
    "$$\n",
    "sim(x,y) = \\frac{xy}{||x||||y||}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T12:26:54.250600Z",
     "start_time": "2021-01-27T12:26:54.236417Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7071067726510136"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定義餘弦相似度\n",
    "def cos_similarity(x: np.ndarray, y: np.ndarray, eps: float=1e-8):\n",
    "    nx = x / (np.sqrt(np.sum(x**2)) + eps)\n",
    "    ny = y / (np.sqrt(np.sum(y**2)) + eps)\n",
    "    \n",
    "    return np.dot(nx,ny)\n",
    "\n",
    "# calculate the similarity between I and you\n",
    "cos_similarity(co_matrix[word2idx['i']], co_matrix[word2idx['you']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立可供查詢相似度的函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T12:27:56.194730Z",
     "start_time": "2021-01-27T12:27:56.177977Z"
    }
   },
   "outputs": [],
   "source": [
    "# 輸入字詞，查詢與此字詞top_n相似的結果\n",
    "def top_k_similarity(query: str, word2idx: dict, idx2word: dict, word_matrix: np.ndarray, top_k: int=3):\n",
    "    # handle the situation of query word not in corpus\n",
    "    if query not in word2idx:\n",
    "        raise ValueError(f\"{query} is not found in input dictionary\")\n",
    "    \n",
    "    # handle the situation of top_k is the same as the amount of words\n",
    "    if top_k >= len(word2idx):\n",
    "        raise ValueError(f\"top_k needs to be less than the amount of words\")\n",
    "        \n",
    "    print(f\"[query] : {query}\")\n",
    "    query_id = word2idx[query]\n",
    "    query_vec = word_matrix[query_id]\n",
    "    \n",
    "    # calculate cosine similarity\n",
    "    similarity_scores = np.zeros(len(word2idx))\n",
    "    for i in range(len(word2idx)):\n",
    "        similarity_scores[i] = cos_similarity(query_vec, word_matrix[i])\n",
    "\n",
    "    # remove query word\n",
    "    similarity_scores[query_id] = 0\n",
    "    filter_word2idx = dict([(k, v) for k, v in word2idx.items() if k != query])\n",
    "    filter_idx2word = dict([(k, v) for k, v in idx2word.items() if k != query_id])\n",
    "    \n",
    "    # sorting by similarity score\n",
    "    top_k_idx = (-similarity_scores).argsort()[:top_k]\n",
    "    top_k_word = [filter_idx2word[word_idx] for word_idx in top_k_idx]\n",
    "    \n",
    "    return dict(zip(top_k_word, similarity_scores[top_k_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T12:27:56.662130Z",
     "start_time": "2021-01-27T12:27:56.651679Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[query] : you\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'and': 0.8660253941251803, 'i': 0.7071067726510136, '.': 0.49999999292893216}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_similarity('you', word2idx, idx2word, co_matrix, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正向點間互資訊(PPMI)\n",
    "由於共生矩陣在高頻字上的缺陷，而PMI中加入了兩字詞共同出現的機率與各自出現的機率的關係，以此解決高頻詞在共生矩陣上的缺陷。\n",
    "而PPMI即將PMI內會產生負值的情況排除(若出現負值則賦予0)\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&PMI(x,y) = log_2\\frac{P(x,y)}{P(x)P(y)} = log_2\\frac{C(x,y)N}{C(x)C(y)} \\\\\n",
    "&PPMI(x,y) = max(0,PMI(x,y))\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T12:28:02.875232Z",
     "start_time": "2021-01-27T12:28:02.859219Z"
    }
   },
   "outputs": [],
   "source": [
    "#定義正向點間互資訊\n",
    "\n",
    "def ppmi(co_matrix: np.ndarray, eps: float=1e-8, verbose: bool=False):\n",
    "    M = np.zeros_like(co_matrix, dtype=np.float32)\n",
    "    N = np.sum(co_matrix)\n",
    "    S = np.sum(co_matrix, axis=0)\n",
    "    total = co_matrix.shape[0]*co_matrix.shape[1]\n",
    "\n",
    "    cnt = 0\n",
    "    \n",
    "    for i in range(co_matrix.shape[0]):\n",
    "        for j in range(co_matrix.shape[1]):\n",
    "            pmi = np.log2(co_matrix[i, j]*N / (S[i]*S[j] + eps))\n",
    "            M[i, j] = max(0, pmi)\n",
    "            \n",
    "            if verbose:\n",
    "                cnt += 1\n",
    "                if cnt % 10 == 0 or cnt == total:\n",
    "                    print(f\"{cnt}/{total} Done\")\n",
    "    \n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T12:28:03.364847Z",
     "start_time": "2021-01-27T12:28:03.345607Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/49 Done\n",
      "20/49 Done\n",
      "30/49 Done\n",
      "40/49 Done\n",
      "49/49 Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aband\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning: divide by zero encountered in log2\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.       , 0.       , 1.7004397, 0.       , 0.       , 0.       ,\n",
       "        0.8930848],\n",
       "       [0.       , 0.       , 0.       , 1.1154772, 0.       , 2.1154773,\n",
       "        0.3081223],\n",
       "       [1.7004397, 0.       , 0.       , 0.7004397, 0.7004397, 0.       ,\n",
       "        0.       ],\n",
       "       [0.       , 1.1154772, 0.7004397, 0.       , 0.7004397, 0.       ,\n",
       "        0.       ],\n",
       "       [0.       , 0.       , 0.7004397, 0.7004397, 0.       , 0.       ,\n",
       "        0.8930848],\n",
       "       [0.       , 2.1154773, 0.       , 0.       , 0.       , 0.       ,\n",
       "        0.8930848],\n",
       "       [0.8930848, 0.3081223, 0.       , 0.       , 0.8930848, 0.8930848,\n",
       "        0.       ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_ppmi = ppmi(co_matrix, verbose=True)\n",
    "output_ppmi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD\n",
    "觀察上面的PPMI輸出矩陣，可以發現大部分的元素都為0(稀疏矩陣)，因此可以發現此矩陣包含了許多無法提供訊息的元素，利用奇異值分解，將矩陣降維，並保存重要的資訊。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T12:28:09.869081Z",
     "start_time": "2021-01-27T12:28:09.846146Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello in co-occurrence matrix: [0 0 0 1 0 1 1]\n",
      "hello in PPMI: [0.        0.        0.        1.1154772 0.        2.1154773 0.3081223]\n",
      "hello in SVD: [-0.5126197   0.5698161   0.39725903 -0.4323913  -0.01054526 -0.124419\n",
      " -0.22839099]\n"
     ]
    }
   ],
   "source": [
    "# 使用np的linalg.svd對PPMI矩陣進行奇異值分解\n",
    "\n",
    "# SVD\n",
    "U, S, V = np.linalg.svd(output_ppmi)\n",
    "\n",
    "# 使用SVD將將原本的稀疏向量轉變為稠密向量\n",
    "print(f\"hello in co-occurrence matrix: {co_matrix[word2idx['hello']]}\")\n",
    "print(f\"hello in PPMI: {output_ppmi[word2idx['hello']]}\")\n",
    "print(f\"hello in SVD: {U[word2idx['hello']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T12:28:10.575312Z",
     "start_time": "2021-01-27T12:28:10.562700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4.0341142e-08 -4.3083389e-08  1.7004397e+00  3.7209105e-08\n",
      "   1.4502533e-09 -4.8094705e-08  8.9308476e-01]\n",
      " [-6.0040975e-08 -5.6422177e-08 -1.3404321e-08  1.1154772e+00\n",
      "  -4.2378574e-08  2.1154773e+00  3.0812228e-01]\n",
      " [ 1.7004398e+00 -7.4432329e-08  5.8041792e-08  7.0043969e-01\n",
      "   7.0043969e-01 -6.8160695e-09  5.6385137e-09]\n",
      " [ 3.5444103e-08  1.1154772e+00  7.0043969e-01  2.3153314e-08\n",
      "   7.0043969e-01  2.0622537e-08  2.2115112e-08]\n",
      " [-4.4883759e-08 -4.3795090e-08  7.0043969e-01  7.0043969e-01\n",
      "  -2.3019233e-08 -8.3527041e-08  8.9308482e-01]\n",
      " [-4.0760728e-08  2.1154773e+00 -7.4080468e-08  2.2216554e-08\n",
      "  -8.4676607e-08 -3.3683197e-08  8.9308482e-01]\n",
      " [ 8.9308482e-01  3.0812228e-01  4.0985121e-08  5.5780403e-09\n",
      "   8.9308482e-01  8.9308482e-01  1.0392343e-08]]\n",
      "[[0.        0.        1.7004397 0.        0.        0.        0.8930848]\n",
      " [0.        0.        0.        1.1154772 0.        2.1154773 0.3081223]\n",
      " [1.7004397 0.        0.        0.7004397 0.7004397 0.        0.       ]\n",
      " [0.        1.1154772 0.7004397 0.        0.7004397 0.        0.       ]\n",
      " [0.        0.        0.7004397 0.7004397 0.        0.        0.8930848]\n",
      " [0.        2.1154773 0.        0.        0.        0.        0.8930848]\n",
      " [0.8930848 0.3081223 0.        0.        0.8930848 0.8930848 0.       ]]\n"
     ]
    }
   ],
   "source": [
    "# 檢查分解是否正確\n",
    "A = U @ np.diag(S) @ V\n",
    "print(A)\n",
    "print(output_ppmi)\n",
    "# 可以發先做完SVD得結果跟原來的output_ppmi是相同的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T12:28:11.413541Z",
     "start_time": "2021-01-27T12:28:11.403536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.9371588  2.5547988  2.1101685  1.9556583  1.1257027  0.58972406\n",
      " 0.30812874]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.29432744, -0.29746115,  0.5294562 ,  0.511355  ,  0.22169203,\n",
       "         0.35262936],\n",
       "       [-0.5126197 ,  0.5698161 ,  0.39725903, -0.4323913 , -0.01054526,\n",
       "        -0.124419  ],\n",
       "       [-0.31352073,  0.30776063, -0.48896635,  0.5457005 , -0.38465765,\n",
       "        -0.12412582],\n",
       "       [-0.33312967, -0.30777904, -0.16466641,  0.03673923,  0.5294517 ,\n",
       "        -0.6964652 ],\n",
       "       [-0.26702777, -0.09261478,  0.3523957 ,  0.24547683, -0.44945022,\n",
       "        -0.26410997],\n",
       "       [-0.48203   , -0.56445074, -0.26282662, -0.430857  , -0.33953863,\n",
       "         0.2642201 ],\n",
       "       [-0.3710324 ,  0.26495245, -0.31999645,  0.0807369 ,  0.45295563,\n",
       "         0.4691856 ]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 可以發現前六個奇異值就佔了絕大多數的奇異值\n",
    "print(S)\n",
    "\n",
    "# 可以取前六個維度當作降為的詞向量\n",
    "U_reduce = U[:, 0:6]\n",
    "U_reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T12:28:14.369342Z",
     "start_time": "2021-01-27T12:28:12.337305Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 將詞向量降為二維方便視覺化\n",
    "U_visualization = U[:, 0:2]\n",
    "\n",
    "# visualization\n",
    "for word, word_id in word2idx.items():\n",
    "    plt.annotate(word, (U_reduce[word_id, 0], U_reduce[word_id, 1]))\n",
    "    \n",
    "plt.scatter(U_reduce[:, 0], U_reduce[:, 1], alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python37364bit6893c7013b164b1189a865dcaea9fb2f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
