{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Day9_作業.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "T51ypp747bAY"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyFMUwWQ7bAe"
      },
      "source": [
        "### 搭建模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvQ7KkEB7bAf"
      },
      "source": [
        "# 一個線性Layer\n",
        "\n",
        "class LinearBNAC(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, bias=True, dropout=0.3, is_output=False):\n",
        "        super(LinearBNAC, self).__init__()\n",
        "        if is_output and out_channels==1:\n",
        "            self.linear = nn.Sequential(\n",
        "                nn.Linear(in_channels, out_channels, bias=bias),\n",
        "                nn.Sigmoid()\n",
        "            )\n",
        "        elif is_output:\n",
        "            self.linear = nn.Sequential(\n",
        "                nn.Linear(in_channels, out_channels, bias=bias),\n",
        "                nn.Softmax(dim=1)\n",
        "            )   \n",
        "        else:\n",
        "            self.linear = nn.Sequential(\n",
        "                nn.Linear(in_channels, out_channels, bias=bias),\n",
        "                nn.Dropout(dropout),\n",
        "                nn.BatchNorm1d(out_channels),\n",
        "                nn.LeakyReLU(inplace=True)\n",
        "            )\n",
        "            \n",
        "    def forward(self, x):\n",
        "        out = self.linear(x)\n",
        "        return out"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXVZMJVD7bAg"
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, input_dimention, output_classes=1):\n",
        "        super(Model, self).__init__()\n",
        "        self.layer1 = LinearBNAC(input_dimention, 128)\n",
        "        # self.layer2 = \"自行定義，只要確定模型能順利運行即可，參數值沒有一定限制\"\n",
        "        # self.layer3 = \"自行定義，只要確定模型能順利運行即可，參數值沒有一定限制\"\n",
        "        self.layer2 = LinearBNAC(in_channels=128, out_channels=64)\n",
        "        self.layer3 = LinearBNAC(in_channels=64, out_channels=32)\n",
        "        self.output = LinearBNAC(32, output_classes, is_output=True)\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.output(x)\n",
        "        return x \n",
        "        "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ub5DM7637bAh"
      },
      "source": [
        "### 準備輸入資料、優化器、標籤資料、模型輸出"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCTUsKNk7bAh"
      },
      "source": [
        "model = Model(input_dimention=256,output_classes=10)\n",
        "# optimizer = \"使用Adam optimizer\"\n",
        "optimizer = optim.Adam(params=model.parameters())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IpWQGzf7bAi",
        "outputId": "7c98d242-0689-4ea1-cdb8-97662e09f116"
      },
      "source": [
        "batch_size = 4\n",
        "input_features = 256\n",
        "dummy_input = torch.randn(batch_size, input_features,)\n",
        "print(dummy_input)      # (4, 256)\n",
        "\n",
        "#target = torch.empty(4, dtype=torch.float).random_(10)\n",
        "target = torch.tensor([9., 5., 4., 4.], dtype=torch.long)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.0804,  0.4898, -0.2529,  ..., -0.5672, -0.0741,  2.1256],\n",
            "        [ 0.1338, -0.4173, -0.9102,  ...,  0.1489, -0.0902,  0.8220],\n",
            "        [ 0.6174,  0.2801,  2.0885,  ...,  0.4467,  0.3066,  2.0640],\n",
            "        [-0.6622, -0.2231,  0.2120,  ...,  0.3078, -1.2583, -1.2880]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBuUsVAx7bAi",
        "outputId": "c0900f54-a7d8-4016-ff54-3d726f2703e6"
      },
      "source": [
        "# output = model(\"自行輸入\")\n",
        "output = model(dummy_input)     # forward!\n",
        "print(output)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.0704, 0.2024, 0.1299, 0.1326, 0.0721, 0.0475, 0.0783, 0.0761, 0.0721,\n",
            "         0.1185],\n",
            "        [0.0597, 0.1553, 0.0513, 0.1006, 0.0588, 0.0895, 0.1494, 0.1273, 0.1169,\n",
            "         0.0912],\n",
            "        [0.0675, 0.2880, 0.0646, 0.0381, 0.0436, 0.0396, 0.1631, 0.0784, 0.1417,\n",
            "         0.0754],\n",
            "        [0.1058, 0.0874, 0.1252, 0.1524, 0.0726, 0.0680, 0.1749, 0.0656, 0.0908,\n",
            "         0.0573]], grad_fn=<SoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouDBbYXw7bAm"
      },
      "source": [
        "### 計算 CrossEntropy Loss\n",
        "* 請注意哪一個 Loss最適合：我們已經使用 softmax\n",
        "* 因為我們有使用dropout，並隨機產生dummy_input，所以各為學員得到的值會與解答不同，然而步驟原理需要相同"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kutRfjLS7bAm"
      },
      "source": [
        "from torch.nn import NLLLoss, LogSoftmax, CrossEntropyLoss"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhBQ_xLG7bAn"
      },
      "source": [
        "# criterion = \"自行輸入\"\n",
        "criterion = CrossEntropyLoss()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SB78VGsK7bAn"
      },
      "source": [
        "# loss = criterion(torch.log(\"自行輸入\"), \"自行輸入\")\n",
        "loss = criterion(output, target)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wwr6SdBV-O3Q",
        "outputId": "564700be-264e-4171-e2cc-ca890e0ba4da"
      },
      "source": [
        "loss"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.3228, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3HEA8oz_hHb",
        "outputId": "bf28a647-3e3f-4757-a2db-8c8075e0ce32"
      },
      "source": [
        "criterion = NLLLoss()\n",
        "\n",
        "loss = criterion(torch.log(output), target)\n",
        "loss"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.5752, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wvAC5Dx7bAn"
      },
      "source": [
        "### 完成back propagation並更新梯度"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td2Shlf27bAo"
      },
      "source": [
        "# \"自行輸入\"\n",
        "loss.backward()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ic4M1LiJ7bAo",
        "outputId": "0df2ad29-810d-44ef-a119-60daa3fbc5be"
      },
      "source": [
        "print('weight : {}'.format(model.layer1.linear[0].weight))\n",
        "print('\\n')\n",
        "print('grad : {}'.format(model.layer1.linear[0].weight.grad))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weight : Parameter containing:\n",
            "tensor([[ 0.0595, -0.0022, -0.0386,  ..., -0.0165,  0.0070,  0.0437],\n",
            "        [-0.0115, -0.0399,  0.0484,  ..., -0.0270,  0.0357, -0.0584],\n",
            "        [ 0.0227,  0.0532, -0.0449,  ..., -0.0619, -0.0274,  0.0181],\n",
            "        ...,\n",
            "        [-0.0475, -0.0574,  0.0475,  ..., -0.0298, -0.0497,  0.0583],\n",
            "        [ 0.0478, -0.0578, -0.0417,  ..., -0.0505, -0.0310, -0.0534],\n",
            "        [ 0.0423,  0.0048, -0.0247,  ..., -0.0152, -0.0225,  0.0141]],\n",
            "       requires_grad=True)\n",
            "\n",
            "\n",
            "grad : tensor([[ 6.1626e-04, -2.5974e-03, -1.5029e-03,  ...,  2.1663e-03,\n",
            "          7.1110e-06, -4.4279e-03],\n",
            "        [-7.5792e-07,  2.4917e-05, -1.6483e-06,  ..., -2.4978e-05,\n",
            "         -2.0186e-06,  1.1238e-04],\n",
            "        [ 3.6274e-03,  1.4770e-03,  8.3650e-03,  ...,  1.4158e-03,\n",
            "          3.2841e-03,  1.0445e-02],\n",
            "        ...,\n",
            "        [-4.0965e-04,  8.3024e-04,  4.2847e-03,  ...,  4.3836e-04,\n",
            "          5.1644e-04, -7.4215e-03],\n",
            "        [ 2.0411e-03,  3.8222e-04,  2.0484e-03,  ...,  3.5787e-04,\n",
            "          2.2498e-03,  5.7886e-03],\n",
            "        [ 9.6183e-03,  1.0799e-02,  5.5137e-03,  ..., -9.0355e-03,\n",
            "          1.6637e-02,  4.6841e-02]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWMJELxK7bAo"
      },
      "source": [
        "# \"自行輸入\"\n",
        "optimizer.step()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUy3mVrp7bAp",
        "outputId": "1c7bad94-9814-40f4-af31-3199e819933c"
      },
      "source": [
        "print('weight : {}'.format(model.layer1.linear[0].weight))\n",
        "print('\\n')\n",
        "print('grad : {}'.format(model.layer1.linear[0].weight.grad))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weight : Parameter containing:\n",
            "tensor([[ 0.0585, -0.0012, -0.0376,  ..., -0.0175,  0.0060,  0.0447],\n",
            "        [-0.0105, -0.0409,  0.0494,  ..., -0.0260,  0.0366, -0.0594],\n",
            "        [ 0.0217,  0.0522, -0.0459,  ..., -0.0629, -0.0284,  0.0171],\n",
            "        ...,\n",
            "        [-0.0465, -0.0584,  0.0465,  ..., -0.0308, -0.0507,  0.0593],\n",
            "        [ 0.0468, -0.0588, -0.0427,  ..., -0.0515, -0.0320, -0.0544],\n",
            "        [ 0.0413,  0.0038, -0.0257,  ..., -0.0142, -0.0235,  0.0131]],\n",
            "       requires_grad=True)\n",
            "\n",
            "\n",
            "grad : tensor([[ 6.1626e-04, -2.5974e-03, -1.5029e-03,  ...,  2.1663e-03,\n",
            "          7.1110e-06, -4.4279e-03],\n",
            "        [-7.5792e-07,  2.4917e-05, -1.6483e-06,  ..., -2.4978e-05,\n",
            "         -2.0186e-06,  1.1238e-04],\n",
            "        [ 3.6274e-03,  1.4770e-03,  8.3650e-03,  ...,  1.4158e-03,\n",
            "          3.2841e-03,  1.0445e-02],\n",
            "        ...,\n",
            "        [-4.0965e-04,  8.3024e-04,  4.2847e-03,  ...,  4.3836e-04,\n",
            "          5.1644e-04, -7.4215e-03],\n",
            "        [ 2.0411e-03,  3.8222e-04,  2.0484e-03,  ...,  3.5787e-04,\n",
            "          2.2498e-03,  5.7886e-03],\n",
            "        [ 9.6183e-03,  1.0799e-02,  5.5137e-03,  ..., -9.0355e-03,\n",
            "          1.6637e-02,  4.6841e-02]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7qbu04P7bAp"
      },
      "source": [
        "### 清空 gradient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jz27R6467bAp"
      },
      "source": [
        "# \"自行輸入\"\n",
        "optimizer.zero_grad()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpq1LFx_7bAp",
        "outputId": "61f6e070-66db-4598-b3f2-281ca4e3fd28"
      },
      "source": [
        "print('weight : {}'.format(model.layer1.linear[0].weight))\n",
        "print('\\n')\n",
        "print('grad : {}'.format(model.layer1.linear[0].weight.grad))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weight : Parameter containing:\n",
            "tensor([[ 0.0585, -0.0012, -0.0376,  ..., -0.0175,  0.0060,  0.0447],\n",
            "        [-0.0105, -0.0409,  0.0494,  ..., -0.0260,  0.0366, -0.0594],\n",
            "        [ 0.0217,  0.0522, -0.0459,  ..., -0.0629, -0.0284,  0.0171],\n",
            "        ...,\n",
            "        [-0.0465, -0.0584,  0.0465,  ..., -0.0308, -0.0507,  0.0593],\n",
            "        [ 0.0468, -0.0588, -0.0427,  ..., -0.0515, -0.0320, -0.0544],\n",
            "        [ 0.0413,  0.0038, -0.0257,  ..., -0.0142, -0.0235,  0.0131]],\n",
            "       requires_grad=True)\n",
            "\n",
            "\n",
            "grad : tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gY1M7Wmv-nrT"
      },
      "source": [
        "# 不需要softmax\n",
        "\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "input = torch.randn(3, 5, requires_grad=True)\n",
        "target = torch.empty(3, dtype=torch.long).random_(5)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6t1eNzOAird",
        "outputId": "4b3244d4-acc2-4b6a-c83e-76670972c141"
      },
      "source": [
        "input"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.4533, -0.9323, -1.2650, -0.0865,  1.4955],\n",
              "        [-0.4729,  1.2305,  0.0577,  1.6709, -0.5790],\n",
              "        [-1.1820, -0.8383, -0.2064,  0.4616, -1.3749]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_e2jigRAjkv",
        "outputId": "6e87c5c6-5265-42b6-db27-3fb7f51cc87f"
      },
      "source": [
        "target"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5glsMskAkQb",
        "outputId": "00df4454-6ba2-4150-afba-6b78e0ae541c"
      },
      "source": [
        "output = loss(input, target)\n",
        "output"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.8565, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEinBfuCAqT8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}